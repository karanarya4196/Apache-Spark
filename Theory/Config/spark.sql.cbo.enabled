## Cost-Based Optimizer

Cost based optimizer is an optimization rule engine which selects the cheapest execution plan for a query based on various table statistics. CBO tries to optimize the execution of the query with respect to CPU utilization and I/O, thus returning as quickly as possible.

Cost Plan:

Last and final part of the piece is how does spark decides which plan execute. Spark uses the statistics computed for the different operation to compute the cost of a query plan. The cost generally has two parts :
 a. CPU cost 
 b. I/O cost

In spark, this is calculated using the following formula:

weight * cardinality + (1 — weight)*size
here, weight is a tuning parameter and can be configured via spark.sql.cbo.joinReorder.card.weight . By default, its value is 0.7.


### FAQ

spark.sql.cbo.enabled=true with Hive table?

Yes CBO (spark.sql.cbo.enabled=true) is useful with Hive tables also.

Explanation:
A HiveTable in Spark is represented by HiveTableRelation class. A Spark table (or a DataSource table) is represented by LogicalRelation class. Both of these classes extends LeadNode. Spark abstracts out the stats of all sorts of LogicalPlan using the "computeStats" method. Every class can gives its implementation for computeStats. If the code we can see that HiveTableRelation class has overridden this method to return table and column level stats if they are available. Same thing is done by LogicalRelation class.
